{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fd524ac-7cd7-40bc-b689-1dda42d4dbc3",
   "metadata": {},
   "source": [
    "# INSTALL LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d6313f4-a57e-4504-84dd-c71c53b9d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install tensorflow_datasets\n",
    "# !pip3 install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3223a7b-d0e8-48f6-982c-0b9f02314637",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a104d9a-a9a3-4a30-b571-c0561465766b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 08:38:15.585486: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-24 08:38:15.613496: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-24 08:38:15.613525: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-24 08:38:15.614579: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-24 08:38:15.619747: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "# Warnings configuration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# General Libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Neural Network Components\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "warnings.filterwarnings('always')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce15928-9418-4f6b-be1f-856985c7b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ANN_creator_module import NeuralNetworkConstructor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503f8169-9d27-4006-a122-3951400145fa",
   "metadata": {},
   "source": [
    "# READING THE DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4693d2a-3939-4245-a045-7325e610b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = '/tf/Face_ID1/list_attr_celeba.txt'\n",
    "df = pd.read_csv(df_path, skiprows=1 ,sep=r'\\s+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2b993af-ab3d-471f-a342-c146c52c8966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7860981-f778-45d0-8355-ddc5bb5ce780",
   "metadata": {},
   "source": [
    "# CREATING THE TENSORFLOW DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78370b51-f4f7-4226-87c7-278e2c53b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '/tf/keras_neural_network/Mis_Tests/img_align_celeba/'\n",
    "resize_factor = 2\n",
    "H = 218 // resize_factor\n",
    "W = 178 // resize_factor\n",
    "img_size = H  # usar H = W si quieres cuadrado\n",
    "batch_size = 32\n",
    "minitrain_size = int(202599*.70)\n",
    "minival_size = int(202599*.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f3c524-aac2-416b-bfec-d4baa83b897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(-1, 0, inplace=True)\n",
    "\n",
    "removed_columns = [\n",
    "    'Sideburns','Wearing_Earrings','Mouth_Slightly_Open','Heavy_Makeup',\n",
    "    'Attractive','Rosy_Cheeks','Wearing_Hat','Wearing_Lipstick',\n",
    "    'Wearing_Necklace','Wearing_Necktie'\n",
    "]\n",
    "df.drop(removed_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bab4905d-1df9-42e6-9918-7c922331f542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202599, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78ea812d-ab1a-4a45-9863-965b0a1f3de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = df.columns\n",
    "y = df[label_cols].values.astype(np.float32)\n",
    "paths = (images_dir + df.index).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9b7761c-1ab3-4f22-9c08-f30979d19c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(paths))\n",
    "np.random.seed(67)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "train_idx = idx[:minitrain_size]\n",
    "val_idx = idx[minitrain_size : minitrain_size + minival_size]\n",
    "\n",
    "train_paths = paths[train_idx]\n",
    "train_labels = y[train_idx]\n",
    "\n",
    "val_paths = paths[val_idx]\n",
    "val_labels = y[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0ceec32-9d3f-44fc-a82d-07470bf2818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (img_size, img_size)) / 255.0\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d247cda-6e00-4e2b-b1fc-5bf368978f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 08:38:17.508404: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-24 08:38:17.514399: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-24 08:38:17.514442: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-24 08:38:17.516440: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-24 08:38:17.516475: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-24 08:38:17.516492: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-24 08:38:17.608456: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-24 08:38:17.608505: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-24 08:38:17.608511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-11-24 08:38:17.608537: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-24 08:38:17.608552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5561 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# ====== MINI TRAIN DATASET ======\n",
    "train_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "    .map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .shuffle(10000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# ====== MINI VAL DATASET ======\n",
    "val_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
    "    .map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb4852d-6cbc-4f05-b928-557e6c95e2ff",
   "metadata": {},
   "source": [
    "# BUILDING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daa382e4-1935-48f9-a561-10982f643635",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_classes = 30\n",
    "inputs = keras.Input((img_size, img_size, 3))\n",
    "x = inputs\n",
    "NNC = NeuralNetworkConstructor(\n",
    "    x, filters=64, total_categories=30, conv_blocks=3, maxpooling_rate=2, \n",
    "    downwards_activations=['relu']*6, downwards_dropouts=[0.3]*3, downwards_regularizers=['L2']*6)\n",
    "\n",
    "conv_outputs = NNC.complete_outputs()\n",
    "# x = layers.GlobalAveragePooling2D()(conv_outputs)\n",
    "x = layers.Flatten()(conv_outputs)\n",
    "\n",
    "x = layers.Dense(\n",
    "    units=556, \n",
    "    activation='relu', \n",
    "    name='Dense1_layer')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "outputs = layers.Dense(\n",
    "    units=30, \n",
    "    activation='softmax', \n",
    "    name='clasification_layer')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7480405-2027-40da-b0f6-c3ae270ba29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79207233-31e7-4cfa-bd60-da63a4453c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DenseNet121(\n",
    "    include_top=False,\n",
    "    input_shape=(H, W, 3),\n",
    "    input_tensor=inputs, pooling=None)\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "780c4aa2-31ed-452b-b986-8d39062f499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = inputs\n",
    "x = base_model(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "outputs = layers.Dense(\n",
    "    units=num_of_classes, \n",
    "    activation='sigmoid', \n",
    "    name='clasification_layer')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b47dc8c5-fff5-4b59-aec3-0ee25bccce53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 109, 109, 3)]     0         \n",
      "                                                                 \n",
      " densenet121 (Functional)    (None, 3, 3, 1024)        7037504   \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 3, 3, 1024)        4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1024)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " clasification_layer (Dense  (None, 30)                30750     \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7072350 (26.98 MB)\n",
      "Trainable params: 6986654 (26.65 MB)\n",
      "Non-trainable params: 85696 (334.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(inputs,outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac0433d-9d56-4766-abe9-e2d1ae1b6505",
   "metadata": {},
   "source": [
    "# TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38baa6b4-db91-447d-9839-f4e01606d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=eval(f\"keras.optimizers.{'RMSprop'}(learning_rate=0.01)\"), \n",
    "    metrics=[\"binary_accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0d5ad29-9ff8-4962-bc8e-a2b688169d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_binary_accuracy',\n",
    "    min_delta=0.001,\n",
    "    patience=10, \n",
    "    restore_best_weights=True,\n",
    "    mode=\"auto\",\n",
    "    verbose=1,\n",
    "    baseline=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad606cf9-52ee-4c2d-b33c-89e10c1e4f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ReduceLROnPlateau = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_binary_accuracy',\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0.00001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2330d99-bc8b-40f7-9b79-6e3bc5646b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCheckpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'my_model.keras',\n",
    "    monitor='val_binary_accuracy',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode=\"auto\",\n",
    "    save_freq=\"epoch\",\n",
    "    initial_value_threshold=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a47fb7-3a1b-4d4d-b723-4a98c056f5f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 08:38:45.581587: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n",
      "2025-11-24 08:38:50.688458: I external/local_xla/xla/service/service.cc:168] XLA service 0x7347b93bbb80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-24 08:38:50.688501: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2025-11-24 08:38:50.693500: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763973530.723283   35806 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2826/4432 [==================>...........] - ETA: 1:43 - loss: 0.3156 - binary_accuracy: 0.8624"
     ]
    }
   ],
   "source": [
    "# # Load the saved model\n",
    "# model = keras.models.load_model('my_model.keras')\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=1000, \n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[early_stopping,\n",
    "              ReduceLROnPlateau,\n",
    "              ModelCheckpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec09458-f418-4c0c-a9ba-375600386165",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271939e4-eb3e-4f68-839d-d225b75bf43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices(\"GPU\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
